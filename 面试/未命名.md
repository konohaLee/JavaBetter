# 6. 高并发秒杀架构：异步解耦与数据一致性设计

在“牛券”项目中，我负责了**优惠券兑换/秒杀**这一核心高并发模块的设计与实现。

秒杀业务瞬时流量极高，对系统有三大挑战：1. **高并发压力**（易压垮数据库）；2. **库存超卖**（并发扣减导致负库存）；3. **用户超领**（并发绕过限领）。

为解决这些难点，我没有采用性能较差的“同步重事务”方案（即API接口内同步操作DB、Redis和MQ），而是直接设计并落地了一套**基于Canal的异步解耦架构**。这套架构在保证了数据最终一致性的前提下，将API接口的性能和吞吐量提升了数倍。

## 1) 核心架构：Redis预检 + DB轻事务 + Canal异步

我的整体架构分为“同步主流程”和“异步解耦流程”两部分。

### A. 同步主流程 (API 接口)：

此流程的目标是极速响应。它只负责最核心的“校验”和“DB事实变更”。

1. **Redis 原子预检 (Lua 脚本)**：我使用 Redis Lua 脚本作为第一道防线，它能原子性地完成“库存校验”、“限领校验”和“预扣减”，彻底杜绝了并发场景下的“读-写”竞态问题。
    
2. **DB 轻量化事务**：在 Lua 校验通过后，我启动一个**编程式事务** (`TransactionTemplate`)，这个事务非常“轻”，只执行两个核心的数据库操作：
    
    - `UPDATE t_coupon_template ...` (使用 `stock >= #{decrementStock}` 的SQL行锁原子扣减MySQL库存)。
        
    - `INSERT INTO t_user_coupon ...` (插入用户领券记录)。
        

事务提交后，API 接口**立刻向用户返回成功**，响应时间控制在毫秒级。

### B. 异步解耦流程 (Canal + MQ 消费者)：

此流程负责所有“后续的、耗时的”工作，确保数据最终一致。

1. **Canal 订阅 Binlog**：我部署了 `Canal` 中间件，配置其伪装成 MySQL 从库，实时订阅 `t_user_coupon` 表的数据库变更日志 (Binlog)。
    
2. **MQ 自动投递**：当 Canal 监听到 `t_user_coupon` 表有 `INSERT` 事件（即上述“轻事务”成功提交）时，它会自动将这条**完整的变更数据**作为消息投递到 RocketMQ。
    
3. **MQ 消费者执行后续**：我编写了一个 MQ 消费者 (`CanalBinlogSyncUserCouponConsumer`) 专门订阅此 Topic。所有原先在“重事务”里的耗时操作，全部转移到这个消费者中**异步执行**：
    
    - **写入 Redis 缓存**：将领券记录写入用户的 ZSet 缓存 (`opsForZSet().add(...)`)。
        
    - **Redis 写后读校验**：为防止 Redis 主从复制延迟或宕机丢数据，我加入了“写后立即读” (`score()`) 的校验逻辑，如果发现 `scored == null`，会**再次写入**以提高成功率。
        
    - **发送延时 MQ**：发送另一条延时消息 (`UserCouponDelayCloseEvent`)，用于优惠券到期后自动更新状态。
        

## 2. 面试官可能问的问题 & 我的回答

---

### **Q1：为什么你选择使用 Lua 脚本来处理 Redis 预扣减？**

> **答：** 这是为了**保证操作的原子性**。秒杀场景下，我需要同时“检查库存是否 > 0”并且“检查用户领取是否 < 限领数”。
> 
> 如果在 Java 代码中分两步执行（`GET stock` -> `GET user_count`），会产生**竞态条件**：当100个并发同时读到 `stock=1` 时，它们都会认为库存充足，导致后续DB层面压力剧增或数据错乱。
> 
> 而 **Lua 脚本在 Redis 中是单线程、原子性执行的**，它可以将“读库存、读限领、写库存、写限领”这多个步骤合并为一次（中途不会被其他命令打断），彻底避免了在缓存层的并发问题。

---

### **Q2：你提到你的方案是“v1改进版”，即DB轻事务 + Canal异步。这个方案对比“同步重事务”的v1（即 type: direct），优势在哪里？**

> **答：** 核心优势是**“事务瘦身”带来的吞吐量提升**。
> 
> 原始的 v1 方案（`type: direct`）在一个数据库事务中，混合执行了：**1. MySQL 写，2. Redis 写，3. Redis 读（校验），4. RocketMQ 写**。
> 
> 这种“重事务”有两个致命缺陷：
> 
> 1. **性能瓶颈**：Redis 和 MQ 的网络 I/O 耗时远高于 DB 操作，导致数据库事务被长时间占用，锁竞争加剧，连接池很快被耗尽，API 响应缓慢。
>     
> 2. **违背事务原则**：事务应该只管理数据库操作。将外部中间件（Redis/MQ）的成败和 DB 事务绑定，如果 MQ 发送失败导致 DB 回滚，这在业务上是不合理的。
>     
> 
> 而我的 **Canal 方案**，将 API 主流程的事务缩减到**只包含两个 MySQL 操作**，执行速度极快，API 吞吐量因此得到数倍提升。

---

### **Q3：你这套 Canal 方案是如何保证“数据一致性”的？万一 Canal 挂了或 MQ 丢消息怎么办？**

> **答：** 我这套架构保障的是**“最终一致性”**，它是通过“可靠事件传递”实现的。
> 
> 1. **源头可靠**：我的异步流程是**基于 MySQL Binlog 驱动的**。Binlog 是数据库层面的变更事实，只要我的“轻事务”成功 `commit`，Binlog 就一定存在。这是最可靠的数据源。
>     
> 2. **Canal 可靠**：Canal 自身支持 HA（高可用）部署，并且它会记录自己消费 Binlog 的位点（position）。即使 Canal 宕机重启，它也会从上次的位点继续订阅，**不会丢失事件**。
>     
> 3. **MQ 可靠**：Canal 投递到 RocketMQ，RocketMQ 自身是高可用的，保证消息不丢失。
>     
> 4. **消费端可靠**：我的消费者（`CanalBinlogSyncUserCouponConsumer`）在执行时（如写 Redis、发延时 MQ），如果失败，MQ 的重试机制会确保任务被再次执行，直到成功。
>     
> 
> 通过这个链路，我确保了“DB变更”这个事实，最终一定能驱动“后续流程”（如写缓存）的完成。

---

### **Q4：你提到在 Canal 消费者里，你做了“Redis 写后读校验”，这是为什么？**

> **答：** 这是为了**对抗 Redis 极端情况下的数据丢失**，主要是指**主从异步复制**带来的风险。
> 
> 场景是：
> 
> 1. 我的消费者向 Redis Master 节点 `add` 缓存数据，Master 返回成功。
>     
> 2. 此时 Master **突然宕机**，而这个 `add` 的数据**还没来得及**异步复制给 Slave 节点。
>     
> 3. Redis 发生故障转移，Slave 成为新 Master，但这个新 Master 上**并没有刚才的数据**。
>     
> 
> 为了缓解这个问题，我在 `add` 之后，立刻执行 `score` **回查**一次。如果 `scored == null`（查不到数据），我就**再次执行 `add`**。这虽然不能 100% 杜绝（如果 Redis 彻底挂了），但它能极大概率地将在“主从切换抖动”瞬间丢失的数据，重新写入到新的 Master 节点上，是一种“尽力而为”的补偿策略，大大提高了缓存写入的成功率。