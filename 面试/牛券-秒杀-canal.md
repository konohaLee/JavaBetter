# 高并发秒杀架构：异步解耦与数据一致性设计

在“牛券”项目中，我负责了**优惠券兑换/秒杀**这一核心高并发模块的设计与实现。
秒杀接口要完成以下任务：
- 1. 操作优惠券库存表进行扣减库存；
- 2. 添加优惠券模板到用户领券表；
- 3. 保存优惠券模板到用户 Redis 领券记录中；
- 4. 查询用户 Redis 领券记录是否持久化成功；
- 5. 发送 RocketMQ 消息队列延时消息，到期修改用户优惠券状态。
秒杀业务瞬时流量极高，对系统有三大挑战：1. **高并发压力**（易压垮数据库）；2. **库存超卖**（并发扣减导致负库存）；3. **用户超领**（并发绕过限领）。

为解决这些难点，我没有采用性能较差的“同步重事务”方案（即API接口内同步操作DB、Redis和MQ），而是直接设计并落地了一套**基于Canal的异步解耦架构**。这套架构在保证了数据最终一致性的前提下，将API接口的性能和吞吐量提升了数倍。

## 1) 核心架构：Redis预检 + DB轻事务 + Canal异步

我的整体架构分为“同步主流程”和“异步解耦流程”两部分。

### A. 同步主流程 (API 接口)：

此流程的目标是极速响应。它只负责最核心的“校验”和“DB事实变更”。

1. **Redis 原子预检 (Lua 脚本)**：我使用 Redis Lua 脚本作为第一道防线，它能原子性地完成“库存校验”、“限领校验”和“预扣减”，彻底杜绝了并发场景下的“读-写”竞态问题。
    - **判断库存是否充足**：检查优惠券的库存 (`stock`) 是否大于 0。如果 `stock <= 0`，就直接返回失败（库存不足）。
    - **判断用户是否超领**：获取用户已领取的次数 (`userCouponCount`)，然后判断这个次数是否已经大于或等于规定的限领次数 (`ARGV[2]`, 即 `limitPerPerson`)。如果超领了，也返回失败（已达上限）。
    - 只有**同时**通过了这两个判断，脚本才会继续往下执行扣减库存 (`HINCRBY -1`) 和增加用户领取次数 (`INCR` 或 `SET`) 的操作。
2. **DB 轻量化事务**：因为既然我们操作数据库了，那么就是要事务，遇到问题我们可以回滚，但是加到整个方法事务又太大了，没必要，因此选择在 Lua 校验通过后，我启动一个**编程式事务** (`TransactionTemplate`)，这个事务非常“轻”，只执行两个核心的数据库操作：
    - `UPDATE t_coupon_template ...` (使用 `stock >= #{decrementStock}` 的SQL行锁原子扣减MySQL库存)。
    - `INSERT INTO t_user_coupon ...` (插入用户领券记录)。
这段 SQL 确实是原子性的，并且它利用了 MySQL (InnoDB) 的**行级锁（Row-level Lock）**机制。我来为你详细拆解一下“为什么”和“怎么样”：

```
<update id="decrementCouponTemplateStock">
    UPDATE t_coupon_template
    SET stock = stock - #{decrementStock}
    WHERE shop_number = #{shopNumber}
      AND id = #{couponTemplateId}
      AND stock >= #{decrementStock}
</update>
```

#### 1. 为什么它是原子性的？

首先，在数据库的 ACID 特性中，**A (Atomicity - 原子性)** 保证一个事务内的所有操作要么全部成功，要么全部失败。而在这里，我们讨论的是**单条 `UPDATE` 语句**，它本身就是数据库执行的最小工作单元，数据库系统（如MySQL）从设计上就保证了**单条语句的执行是原子的**。

但是，在“秒杀”这个**并发（Concurrency）场景下，我们所说的“原子性”通常是指：“读取库存、判断库存、扣减库存”这三个动作必须捆绑在一起，不被其他线程插队。**

而你展示的这条 SQL 语句，恰好就实现了这个效果。

#### 2. 它是如何利用 MySQL 行锁的？

你理解这个机制的关键，在于明白 `UPDATE` 语句在 `InnoDB` 存储引擎下的工作流程：

**前提：** 假设 `id` 字段是主键或索引。

**执行流程：**

1. **查找行 (Find)：** 当一个事务（比如线程A）执行这条 `UPDATE` 语句时，MySQL 会根据 `WHERE` 子句（`shop_number = ? AND id = ?`）去查找目标数据行。
2. **获取锁 (Lock)：**
    - 为了防止其他事务同时修改这一行，`InnoDB` 会在找到的这行数据上**加一个排他锁（Exclusive Lock，也叫 X-Lock 或写锁）**。
    - **排他锁的核心特性：** 一旦线程A获取了这行的锁，**其他任何**试图修改（`UPDATE`, `DELETE`）或加锁（`SELECT ... FOR UPDATE`）**同一行**的线程（比如线程B）都必须**排队等待**，直到线程A的事务提交并释放这个锁。
3. **判断条件 (Check)：**
    - 线程A在**持有锁**的情况下，开始检查 `WHERE` 子句中的最后一个条件：`AND stock >= #{decrementStock}`（比如 `stock >= 1`）。
4. **执行更新 (Update)：**
    - **如果条件满足 (stock >= 1)：** 线程A执行 `SET stock = stock - 1`，将库存减 1。
    - **如果条件不满足 (stock < 1)：** 线程A什么也不做。
5. **释放锁 (Unlock)：** 线程A的事务提交，释放这把行锁。

#### 3. 用“秒杀最后一件商品”来模拟并发

假设现在库存 (stock) 只剩下 `1`，此时两个用户（线程A 和 线程B）**同时**点击“抢购”，它们都执行了这条 SQL。

**在 MySQL 内部会发生这样的“排队”：**

1. 线程A 和 线程B 几乎同时到达 MySQL，都想更新 `id = 123` 这一行。
2. MySQL 的锁管理器**只会让一个线程（比如 线程A）先获得这行的排他锁**。
3. **线程B** 获取锁失败，进入**阻塞等待**状态（它在排队）。

**线程A 的执行（拿到锁）：**

- **查找：** 找到 `id = 123` 的行。
- **加锁：** 成功获取排他锁。
- **判断：** 检查 `WHERE` 条件。此时 `stock` 是 `1`，`1 >= 1` **成立**。
- **更新：** 执行 `SET stock = 0`。
- **提交：** 事务提交，**释放锁**。
- **返回：** `UPDATE` 语句返回“受影响的行数 (rows affected)”：**1**。
---
**线程B 的执行（终于排到队，A已释放锁）：**

- **加锁：** 终于获取到了这行的排他锁（此时线程A已提交）。
- **判断：** 检查 `WHERE` 条件。**注意！** 此时这行的 `stock` **已经是 `0`**（被线程A改过了）。
- MySQL 检查 `stock >= 1`，即 `0 >= 1`，条件**不成立**。
- **更新：** 由于 `WHERE` 条件不满足，`SET` 语句**不会被执行**。
- **提交：** 事务提交，释放锁。
- **返回：** `UPDATE` 语句返回“受影响的行数 (rows affected)”：**0**。

#### 总结

这就是为什么这条 SQL 是原子且线程安全的：

1. **行锁的排他性：** 保证了在任何一个时刻，只有**一个**线程能“操作”这行数据，其他线程必须排队，实现了**并发操作的“串行化”**。
2. **`WHERE` 条件的原子性：** `AND stock >= #{decrementStock}` 这个条件判断，是在**持有锁**的情况下进行的。这确保了从“检查库存”到“扣减库存”的整个过程，中间不会有其他线程插进来修改 `stock` 值。

这个 `UPDATE ... WHERE stock >= ...` 的技巧，是在数据库层面实现**乐观锁（CAS，Compare-And-Set）思想**的经典用法。
事务提交后，API 接口**立刻向用户返回成功**，响应时间控制在毫秒级。

### B. 异步解耦流程 (Canal + MQ 消费者)：

^b4c343

此流程负责所有“后续的、耗时的”工作，确保数据最终一致。

1. **Canal 订阅 Binlog**：我部署了 `Canal` 中间件，配置其伪装成 MySQL 从库，实时订阅 `t_user_coupon` 表的数据库变更日志 (Binlog)。
2. **MQ 自动投递**：当 Canal 监听到 `t_user_coupon` 表有 `INSERT` 事件（即上述“轻事务”成功提交）时，它会自动将这条**完整的变更数据**作为消息投递到 RocketMQ。
3. **MQ 消费者执行后续**：我编写了一个 MQ 消费者 (`CanalBinlogSyncUserCouponConsumer`) 专门订阅此 Topic。所有原先在“重事务”里的耗时操作，全部转移到这个消费者中**异步执行**。这个消费者的前提是，它只监听 `t_user_coupon`（用户领券表）的 `INSERT` 事件，也就是只在新用户领券记录**成功插入数据库后**才会被触发。

- **添加用户领券缓存**：
    - 它从 `Canal` 推送过来的 `INSERT` 事件中解析出 `user_id`、`coupon_template_id` 和新生成的 `userCouponId`。
    - 然后，它将这个领券记录添加到 Redis 的 `ZSet` 缓存中（`key` 是用户的 `USER_COUPON_TEMPLATE_LIST`，`value` 是 `券模板ID_用户券ID`，`score` 是领取时间）。
    - 这个缓存是用来给用户查询“我的优惠券”列表时使用的。
- **执行“写后读”校验（保证缓存成功）**：
    - 这是为了防止 Redis 因为主从复制延迟或宕机导致缓存丢失。
    - 在（1）写入缓存后，它立刻执行 `opsForZSet().score()` **回查**刚写入的数据。
    - 如果 `scored == null`（意味着查不到，数据可能丢失了），它会**再次执行一次 `add` 操作**，尽最大努力确保缓存写入成功。
- **发送延时消息（用于券过期）**：
    - 它从 `INSERT` 事件中获取优惠券的到期时间 (`valid_end_time`)。
    - 然后，它构建并发送一个**新的 RocketMQ 延时消息** (`UserCouponDelayCloseEvent`)。
    - 这个延时消息会在优惠券到期时被消费，用于后续自动将优惠券状态从“未使用”更新为“已过期”。

## 2. 面试官可能问的问题 & 我的回答
### Q1：你为什么要把“重事务”方案重构成“DB轻事务 + Canal异步”的架构？

**答：** 核心目标是**大幅提升API的吞吐量和响应速度**。

- **“重事务”方案的瓶颈**：它在**一个数据库事务**中，混合执行了 MySQL 操作、Redis 写入、Redis 读取、RocketMQ 发送。Redis 和 MQ 的操作都涉及**网络I/O**，这会导致数据库事务的**持有时间过长**，锁竞争加剧，在高并发下连接池会迅速耗尽，导致API响应缓慢。
    
- **“轻事务 + Canal”的优势**：我将事务“瘦身”，API 主流程的事务**只负责两个核心的数据库操作**（扣库存和插记录）。这个事务执行极快，API 几乎可以瞬时响应。
    
- 而所有**耗时且非核心**的后续工作（如：写缓存、发延时消息），我都剥离出去，通过 `Canal` 监听 `Binlog` 来**异步执行**。这样就解耦了核心流程和辅助流程，极大提升了系统的并发处理能力。
    

---

### Q2：你这套Canal异步架构，是如何保证数据一致性的？

**答：** 这套架构保障的是**“最终一致性”**，它依赖一个“可靠的事件传递”链条：

1. **源头可靠（Binlog）**：我的异步流程是**基于 MySQL Binlog 驱动的**。`Binlog` 是数据库变更的“事实”记录，只要“轻事务”成功提交，`Binlog` 就**一定**存在，这是最可靠的数据源。
    
2. **捕获可靠（Canal）**：`Canal` 会记录它消费 `Binlog` 的位点（position）。即使 `Canal` 宕机重启，它也会从上次的位点继续订阅，**确保事件不丢失**。
    
3. **投递可靠（MQ）**：`Canal` 将变更事件投递到 `RocketMQ`，MQ 自身是高可用的，能保证消息在投递阶段不丢失。
    
4. **消费可靠（Consumer）**：我的消费者（`CanalBinlogSyncUserCouponConsumer`）在执行时（如写 Redis），如果失败，`RocketMQ` 的**重试机制**会确保该消息被重新消费，直到成功为止。
    

通过这个“DB事实 -> Canal -> MQ -> 消费者重试”的链条，确保了数据最终一定能同步。

---

### Q3：你为什么在主流程里还要用 Lua 脚本？数据库SQL不是已经有 `WHERE stock >= ...` 在校验了吗？

**答：** 这是为了**“分层过滤”，用高性能的 Redis 来保护昂贵的数据库资源**。

- **Redis (Lua) 是第一道防线**：它的执行成本极低（内存操作），速度最快。在秒杀场景下，99%的请求都是“库存不足”或“用户超领”的无效请求。我用 Lua 脚本在**缓存层**就把这些海量请求全部拦截掉。
    
- **Database (SQL) 是最后一道防线**：对于极少数通过了第一道防线的并发请求（比如 10 个请求同时抢最后 1 个库存），`UPDATE ... WHERE stock >= 1` 这条 SQL 会利用**数据库行锁**，强制它们**串行执行**。只有第一个请求能返回“影响行数为1”（扣减成功），后续请求都返回0（扣减失败），从而**保证了数据在数据库层面的绝对一致性**，防止超卖。
    

如果没有 Lua 这层拦截，所有请求都会打到数据库去竞争行锁，数据库会瞬间崩溃。

---

### Q4：在Canal消费者中，你为什么要执行“Redis写后读校验”？

**答：** 这是为了**对抗 Redis 极端情况下的数据丢失**，主要是指**主从异步复制**带来的风险。

- **风险在于**：`Redis` 主从复制是异步的。当消费者向 `Master` 节点写入缓存并收到成功响应后，如果 `Master` 在**同步给 `Slave` 之前**突然宕机，`Slave` 切换为新 `Master`，那么这条刚写入的缓存数据就**永久丢失**了。
    
- **我的补偿措施（写后读）**：在 `add` 写入后，我立刻用 `score` 命令**回查**一次。如果返回 `null`（查不到），这就是一个数据可能丢失的危险信号。此时，我会**再次执行一次 `add` 操作**，尝试将数据写入新的 `Master` 节点。这是一种“尽力而为”的补偿策略，能极大提高缓存写入的成功率。
    

---

### Q5：你的Canal消费者收到消息后，为什么还要再发送一个“延时消息”？

**答：** 因为**这两个消息的业务职责完全不同**。

1. **Canal 发来的（即时消息）**：代表“一个领券记录**已成功**插入数据库”。消费者（`CanalBinlogSyncUserCouponConsumer`）的职责是**同步缓存**，即把这个“事实”同步到 Redis，让用户能**立刻**查到这张券。
    
2. **消费者发出的（延时消息）**：代表“这张券**未来会过期**”。这个 `UserCouponDelayCloseEvent` 消息的目的是在券的 `valid_end_time`（例如48小时后）被消费，用于触发“**自动更新优惠券状态为已过期**”的这个**未来**的业务。
    

我把“发延时消息”这个动作也从主事务中剥离出来，放到 Canal 消费者中，也是“事务瘦身”的一部分。

---

### Q6：你在主流程的“轻事务”里，是如何处理 `DuplicateKeyException`（用户重复领取）异常的？

**答：** 我在 `TransactionTemplate` 的 `try-catch` 块中对这个异常进行了捕获和处理，以**保证数据一致性**。

- **问题**：当 `INSERT`（插记录）因为“唯一键冲突”失败时，在这之前的 `UPDATE`（扣库存）可能已经成功了。如果不做处理，就会导致用户没领到券，库存却被扣减的 Bug。
    
- **我的处理**：
    
    1. 当 `catch` 块捕获到 `DuplicateKeyException` 时，我首先会**显式地调用 `status.setRollbackOnly()`**。
        
    2. 这个调用会**强制整个事务回滚**，从而**撤销**掉前面已经执行的 `UPDATE`（扣库存）操作，把库存还回去。
        
    3. 最后，我再 `throw new ServiceException("用户重复领取优惠券")`，给前端返回一个清晰的业务提示。