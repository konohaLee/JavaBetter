# 怎么用责任链创建优惠券模板

在优惠券模块开发中，我负责了“优惠券模板创建业务”的整体设计与实现。

这个模块的业务逻辑相对复杂，比如：不同类型的优惠券（平台券和店铺券）、优惠对象（商品专属或全店通用）、领取规则、消耗规则等都有较多的参数要求，导致参数校验逻辑变得非常冗长。

一开始我是在 `createCouponTemplate` 接口中手动写了大量 if 判断，对请求参数做各种非空和业务合法性校验。但后期维护成本非常高，比如一旦新增一个校验逻辑，就容易改动一大坨代码，还容易出错。

为此我对这块逻辑做了架构优化 —— **采用责任链模式** 把所有校验拆成独立模块，每个校验逻辑封装成一个处理器，实现了高度解耦、职责单一。

我定义了一个统一的责任链接口 `MerchantAdminAbstractChainHandler<T>`，每个处理器都实现它，并注册进 Spring 容器。责任链上下文 `MerchantAdminChainContext` 会在启动时收集所有实现类，并根据业务标识（如：优惠券模板创建）进行排序和调度。这样在创建优惠券时，只需要调用：

```
merchantAdminChainContext.handler(MERCHANT_ADMIN_CREATE_COUPON_TEMPLATE_KEY, requestParam);
```

框架就会自动按照顺序去执行每个校验逻辑（比如非空校验、数据格式校验、商品合法性校验等），而不用手动管理调用流程。

此外，我还结合了缓存预热（使用 Redis Hash + Lua 脚本设置过期时间）确保优惠券库存在上线时自动写入缓存并可原子性过期；并使用 JSON 存储领取规则和消耗规则，方便后续灵活扩展。

## 为什么用责任链，有什么优势

因为优惠券模板创建的参数验证逻辑非常多，比如非空、格式合法性、库存是否为正、商品是否存在等等，后期还可能新增新的校验规则。

传统方式是把所有逻辑写在一个方法里，非常臃肿，违反了“单一职责原则”。而责任链模式可以将每一个校验逻辑抽象成一个处理器，职责明确、互不影响，新增或移除某个校验只需操作一个类，符合“开闭原则”。

并且我通过 Spring 容器自动收集、排序这些处理器，避免了硬编码，增强了通用性和可扩展性。

## 如果某个处理器执行失败了，怎么处理？责任链是继续往下走还是中断？

我设计的时候是根据不同校验的严重程度决定：

- 如果是**强校验**（比如缺少必须参数），会直接抛出异常，中断后续处理；
- 如果是**可容忍的校验**（比如字段格式不规范但不影响业务逻辑），可以记录日志并继续往下走。

这个机制是在每个处理器中通过异常机制控制的。责任链上下文只是负责顺序执行，并不会强制处理异常，由各处理器自行决定是否抛出错误。

## 你是怎么保证责任链执行顺序的？如果顺序错了会不会影响业务？

我让每个处理器实现了 Spring 的 `Ordered` 接口，通过返回 `getOrder()` 值来指定执行优先级。系统启动时我在 `MerchantAdminChainContext.run()` 方法中，对每一组责任链按顺序进行排序。

比如：非空校验是最基础的，它优先级最低（值最小），会最早执行；像商品是否存在这类依赖性强的逻辑，会排在后面执行。

这确保了处理流程的正确性，也避免了因为顺序错误导致依赖数据为空的异常。

## 如果后续要新增一个新的校验逻辑，比如优惠券时间不能小于当前时间，该怎么做？

只需要新增一个实现了 `MerchantAdminAbstractChainHandler<T>` 的校验处理器类，并设置好其 `mark()` 与 `getOrder()` 方法：

# 分库分表

在我们的优惠券模板创建业务中，主力用户是商家，根据市场数据估算，全国大概有 3000 万商家。如果每个商家平均创建 100 张优惠券模板，整个系统会产生近 30 亿条优惠券模板数据。因此，为了满足大数据量下的查询性能和写入效率，我在这一模块主导了**分库分表方案的设计与落地**，整个过程主要包含以下几个关键步骤：

### 1）业务分析与预估数据量

首先，我根据非官方统计数据以及平台过往的商家行为，对商家数量和每个商家的平均优惠券创建量进行了保守预估，从而得出整个优惠券模板表最终可能达到的规模大约为 30 亿。

同时也考虑到这个数据量是随着时间不断增长的，因此我们一开始就选择了支持**大规模扩展的架构**。

------

### 2）分析是否适合分库分表

从业务特性来看，优惠券模板表满足两个典型条件：

- 数据总量大（亿级别）
- 虽然写入频率不高，但查询频率较高，且后续有分发、领取等高并发业务依赖于此表

因此我最终选择了 **分库 + 分表** 的方案。

------

### 3）选择分片键

在实际业务中，我们发现大部分对优惠券模板的操作，比如“查看某个商家下的模板列表”，都是基于商家维度的，因此我选用了 `shop_number` 作为**分片键**。

分片键选型主要考虑了三个维度：

- 数据分布是否均匀
- 是否能避免跨库跨表操作
- 是否是稳定字段（不可变）

shop_number 完全符合以上条件。

------

### 4）初始分库分表策略设计

初版设计是：**2 个库，每库 8 张表，共 16 张物理表**。采用 HashMod 分片算法对 `shop_number` 进行取模，决定数据落库和落表位置。

并通过 `ShardingSphere` 管理分片规则，它的优势在于配置灵活、生态完善、且社区活跃，是 Apache 顶级项目，兼容性也很好。

------

### 5）发现 HashMod 导致分布不均问题

我们在做 Mock 数据测试时发现：

- 某些表的数据几乎为空，其他表爆满
- 分库时存在“0库都是奇数表”、“1库都是偶数表”的情况

原因是 Hash 后模运算结果和库表结构刚好冲突，导致**分片倾斜严重**。

------

### 6）自定义分片算法改进

为了解决分布不均问题，我自定义了分库与分表的分片算法：

- 基于 `hashShardingValue(id)` 对分片键做扰动处理
- 使用 `shardingCount` 控制总的分片数，保证数据均匀落到不同库和表
- 然后根据分片编号动态映射到目标库表名

最终通过单元测试验证，50,000 条模拟数据能够均匀分布，解决了之前分布不均的隐患。

------

### 7）SQL 路由与查询优化

我还特别注意了 SQL 路由层面的问题：

- 查询必须带分片键，避免读扩散
- 逻辑库、逻辑表设计上与物理结构解耦，代码无需改动
- 开启 SQL 打印，辅助开发排查路由行为是否正确

### Q1：为什么一开始不选择使用分布式数据库，比如 TiDB？

答：我们评估了 TiDB、PolarDB 等分布式数据库，发现：

- 兼容性不是完全 100%，迁移成本高
- 部分需要商业授权，成本高于自建 MySQL
- 社区版 TiDB 存在较多 Issue，不适合生产环境

而 ShardingSphere 是轻量级中间件，兼容 MySQL，且对我们这类“写入频次不高，读为主”的业务更友好。

------

### Q2：为什么你们不用时间范围分片，而选择了哈希取模？

答：时间分片适合数据“随时间稳定增长”的业务，比如日志、订单。但在我们这个业务中，商家注册和活跃行为分布非常不均匀：

- 早期商家少
- 新商家后期会突然活跃、集中创建优惠券

时间维度在这里不能做到数据均匀，所以我选择了 Hash，并在后续通过自定义 Hash 算法进一步解决分布不均问题。

------

### Q3：你们是怎么选分片数量的？为什么是 2 库 16 表？

答：我们设定单表承载上限为 2000 万行，30 亿数据就需要约 150 张表。但考虑到：

- 当前业务并发不高，不需要立即分这么多
- 我们可以用 ShardingSphere 实现配置扩容而不影响代码

所以我先选了一个比较均衡的结构（2 库 * 8 表），满足当前负载，后续扩容可以平滑切换。

------

### Q4：如果查询条件不带分片键怎么办？

答：这种查询就会触发读扩散，ShardingSphere 会对所有分片表执行查询，再用 UNION ALL 合并结果。

这对性能影响极大，因此我们在接口层做了明确的参数校验，如果查询不带 `shop_number` 就拒绝处理。同时，在 ShardingSphere 配置中开启了 SQL 日志，方便排查是否触发了跨分片查询。

------

### Q5：你们有没有考虑将分库、分表分别设计？而不是一起做？

答：有考虑过，但因为我们业务特点是：

- 写并发低，分库不是必需
- 数据量大，分表是刚需
- 后续分发、领取需要高并发支撑，未来可能对分库有需求

因此在设计初期，我们**一开始就做了分库分表的整体架构规划**，尽管当前场景分表为主，但为未来扩展预留了空间。

# 自定义重复提交注解

### 一、我做了什么

在我们优惠券管理系统中，商家创建优惠券是一个频繁操作点。早期测试时发现，商家在点击“创建”按钮时，有一定概率会触发重复提交，比如因为网络卡顿多次点击、页面刷新、系统响应延迟等。为了保证数据一致性、避免重复入库，我主导实现了一个**防重复提交功能**。

这个功能一开始我用的是 Redisson 实现的分布式锁，并结合请求路径、用户ID、参数MD5 构建唯一的锁 Key。逻辑很简单：业务代码执行前尝试加锁，加锁失败就说明重复提交，直接抛异常；成功则执行业务逻辑，最后释放锁。

但我很快发现，如果每个业务方法都写一遍锁逻辑，冗余且容易出错，于是我把它**封装成一个可复用的通用组件**。具体来说，我：

- 设计了一个注解 `@NoDuplicateSubmit`，使用者只需要加在方法上即可；
- 用 Spring AOP 拦截标注的方法，统一处理锁的加解逻辑；
- 锁 Key 生成逻辑通过 SpEL 组合 servletPath、userId 和参数 MD5，确保唯一性；
- 封装为 framework 层组件，并通过自动配置类和 `spring.factories` 统一加载；
- 最终我们在 Controller 层只需加一个注解，整个流程即可防止重复提交；
- 我还使用 JMeter 做了并发压测，模拟 20 个线程同时请求，只允许一个进入，验证通过。

这部分现在已经沉淀为我们项目的基础能力组件，未来也可以支持防 MQ 消费幂等等扩展。

------

### 二、面试官可能问的问题和我的回答

------

**Q1：为什么你不用前端禁用按钮或者 token 防重复？**

> A：前端禁用是第一道防线，但并不可靠，比如用户刷新页面、手动发包、页面加载卡顿等都会绕过前端逻辑。而 token 模式虽然常见，但维护起来比较重，需要服务端记录和校验 token 状态，侵入性强。相比之下，基于 AOP + 分布式锁的方式不仅无侵入、还支持高并发场景下幂等校验，适合我们这种 B 端操作频繁、逻辑简单的场景。

------

**Q2：你是怎么生成唯一的分布式锁 Key 的？怎么确保它不会误判？**

> A：我设计的 Key 由三部分组成：请求路径（ServletPath）、当前用户ID、请求参数的 MD5。这样即便同一个用户频繁访问不同接口、或者同一个接口用不同参数请求，都能区分开来。只有完全一样的操作才会命中锁，误判率可以忽略不计。

------

**Q3：你这个分布式锁是怎么实现的？有超时时间吗？**

> A：我用的是 Redisson 提供的可重入锁 `RLock`，通过 `tryLock()` 尝试加锁。这里可以设置等待时间和自动释放时间，防止死锁。我测试发现默认行为已经能很好地满足我们的需求。如果进一步细化，我们可以配合 `tryLock(long waitTime, long leaseTime)` 控制锁持有的生命周期。

------

**Q4：为什么不用数据库唯一约束、或者乐观锁来做防重复？**

> A：数据库唯一约束适合强一致性场景，但我们优惠券的主键是雪花 ID，不具备天然唯一性，也不适合给所有字段都加唯一索引，性能开销太大；而乐观锁更多用于更新场景，创建操作无法通过 version 字段控制，因此我认为分布式锁在这里更合适。

------

**Q5：你如何验证这个功能在并发情况下有效？**

> A：我用 JMeter 启动了 20 个线程并发请求创建接口，并手动在逻辑中加入 `Thread.sleep()` 放大处理时间。在 Redisson 分布式锁保护下，只有一个线程能成功创建，其他线程全部被挡下并返回“请勿重复提交”的提示，验证结果完全符合预期。

------

**Q6：为什么不直接在 Service 层处理，而要搞个 AOP 组件？**

> A：一开始我就是在 Service 层加锁的，但后面发现很多接口都有这个需求，复制代码容易出错、维护成本高。所以我通过 AOP 切面做了抽象，并定义注解作为标识。这样业务逻辑可以和幂等逻辑解耦，既简洁又通用，符合开闭原则。

------

**Q7：这个组件如果用在其他业务上，比如订单提交，还需要改吗？**

> A：不需要改核心逻辑，只需要在订单 Controller 方法上加 `@NoDuplicateSubmit` 注解即可。唯一需要保证的，是参数对象要有良好的 `toString()` 或能正确被 JSON 序列化生成唯一 MD5，保证幂等性判断准确。

------

**Q8：有没有考虑 Redis 节点宕机或锁失效的情况？**

> A：是的，Redisson 的分布式锁支持自动过期机制，如果服务节点异常退出，锁也会释放，不会死锁。当然，为了增强健壮性，也可以配合 WatchDog 自动续期，或者使用 Redisson 提供的公平锁/可重入锁机制。我们当前部署是 Redis 高可用 + 主备切换，所以风险是可控的。

------

**Q9：这个组件支持集群部署吗？**

> A：完全支持。分布式锁本身是基于 Redis 实现的，多个服务节点间共享 Redis 实例，所以无论部署多少台，只要锁 Key 一致，幂等机制就能生效。

# 优惠券异步推送

在优惠券任务模块中，商家上传包含大量用户的 Excel 文件来批量发送优惠券。之前我们使用 EasyExcel 做了解析优化，解决了内存 OOM 的问题，但接口响应时间依旧较长（百万行数据大概需要 4~5 秒），影响了用户体验。

为了提升接口响应速度，我引入了线程池异步处理 + Redis 延时队列兜底的双重保障机制：

1. **使用线程池异步解析 Excel 行数**
    我在服务类中定义了一个线程池，用于异步执行解析任务，避免阻塞主线程，从而将接口响应从原来的 5 秒优化到了毫秒级。具体来说，将原来通过 EasyExcel 解析 Excel 总行数的逻辑封装成 `refreshCouponTaskSendNum()` 方法，并通过线程池投递执行。
2. **引入 Redis 延时队列作为宕机兜底机制**
    考虑到线程池任务尚未执行应用就可能宕机，我使用 Redisson 的延时队列在接口请求完成后再提交一次延迟任务，确保数据最终一致性。延迟时间设置为 20 秒，足够覆盖正常线程池处理时间。
3. **设计幂等消费逻辑，避免重复执行**
    在延时队列的消费者逻辑中，我判断数据库中该任务是否已经被线程池处理过（sendNum 是否为空），为空才重新处理，从而保证幂等性。
4. **统一纳入 Spring 事务管理**
    为防止主流程插入数据库成功而线程池和队列逻辑未执行，我将整个创建逻辑放入 Spring 声明式事务中，保证原子性。

------

### 面试官可能会问的问题 & 回答

------

**Q1：为什么不直接用消息队列来处理异步逻辑？**

> 这确实是一个常见做法，我们项目里有消息队列（如 RocketMQ），但出于业务隔离考虑，这个模块没有直接接入 MQ。另外，考虑到一些中小型项目可能本身没有消息中间件，我尝试用 Redis 延时队列来模拟类似效果，提供一个更轻量级的替代方案。同时这也能锻炼我对 Redis 高级特性的掌握能力。

------

**Q2：为什么要加 Redis 延时队列，线程池不是已经异步处理了吗？**

> 是的，线程池已经能加快处理，但它有一个天然缺陷：如果请求刚提交，线程池任务还没执行完，服务突然宕机，数据就可能永远不处理了。为了容错，我使用 Redis 延时队列作为兜底补偿机制，确保就算线程池没跑完，还有一个备份计划在 20 秒后再次尝试。

------

**Q3：为什么延迟时间选 20 秒？这个值怎么确定的？**

> 我们做过多次压测，解析百万行 Excel 的任务在正常情况下 4 秒以内可以完成，考虑到 IO 抖动、GC 等因素，我设置了一个较为安全的缓冲时间：20 秒，确保主线程池足够完成任务，而延迟队列是兜底用，不会冲突也不会重复处理。

------

**Q4：你是怎么保证延迟队列任务不被重复处理的？**

> 我在延迟队列消费逻辑中加了判断逻辑：查询该任务在数据库中的 sendNum 字段，如果不为空说明线程池已经处理过了，就跳过。如果为空才执行。这种幂等性判断也适用于实际消息队列的消费策略。

------

**Q5：如果 Redis 延时队列宕机怎么办？会不会丢任务？**

> Redis 本质是缓存，确实有持久化失败的可能，所以这套机制是「快速响应 + 高可用兜底」的组合，不是「强一致性」。生产环境我们会在告警、日志监控上兜底，甚至用 MQ 做二次保障或人工补偿。后续也可以把延迟队列逻辑统一迁移到 MQ。

------

**Q6：你为线程池配置的参数是怎么考虑的？**

> 我们任务属于 IO 密集型，我设置了：

- 核心线程数为 `CPU 核心数`；
- 最大线程数为 `CPU 核心数 x 2`；
- 工作队列用 `SynchronousQueue`，任务直接交给线程执行；
- 拒绝策略为 `DiscardPolicy`，丢弃任务但不会抛异常，避免影响主流程。

另外任务失败还有 Redis 兜底，能最大程度提升处理效率和稳定性。

------

**Q7：你为什么给方法加了事务注解？**

> 因为我们要确保的是「数据库插入任务记录」和「异步任务投递（线程池 & 延迟队列）」要么都成功、要么都失败。如果不加事务，中间挂了就可能出现数据库有任务记录但没有解析数据的情况。所以我加了 `@Transactional(rollbackFor = Exception.class)` 保障原子性。

# 模板方法重构消息队列发送

在优惠券系统中，用户可以创建**立即发送**或**定时发送**的分发任务。对于立即发送类型，我们需要在任务创建后立即触发 RocketMQ 消息，通知分发服务执行发放流程。最初的实现中，RocketMQ 的发送代码嵌套在业务逻辑中，存在以下问题：

- 大量重复构建消息、构造 topic、发送日志打印的代码；
- 和核心业务逻辑耦合度过高；
- 业务拓展困难，比如需要切换 tag、延迟发送等。

为了提升可维护性和扩展性，我对 RocketMQ 的消息发送流程做了**结构性重构**，引入了**模板方法设计模式**。整体改造包括以下几个方面：

### 1. 发送逻辑抽象化

我封装了一个抽象类 `AbstractCommonSendProduceTemplate<T>`，内部统一定义：

- 构建消息实体 `buildMessage(...)`
- 构建扩展配置（topic、tag、key 等）`buildBaseSendExtendParam(...)`
- 封装 `sendMessage(...)` 方法作为模板方法：统一调用 RocketMQ API、封装 try-catch、打印日志。

### 2. 消息体封装与事件标准化

为确保消息体结构标准、易于拓展，我定义了两个结构体：

- `BaseSendExtendDTO`：封装通用消息配置，如 topic、tag、keys 等；
- `MessageWrapper<T>`：将实际消息体统一包裹，加入发送时间、唯一 key。

并对每类业务场景定义专属 Event 对象，如 `CouponTaskExecuteEvent`。

### 3. 消息发送生产者实现

以“优惠券立即发放任务”为例，我实现了具体的 `CouponTaskActualExecuteProducer`：

- 继承 `AbstractCommonSendProduceTemplate`
- 实现上述两个抽象方法，指定业务配置（topic、key 等）与消息体构建方式；
- 在实际业务逻辑中，调用仅需一行代码：

```
java


复制编辑
couponTaskActualExecuteProducer.sendMessage(CouponTaskExecuteEvent.builder().couponTaskId(id).build());
```

### 4. 消费者同步改造

由于我们对消息体做了统一包装，因此消费端也做了统一适配。所有消费类均以 `RocketMQListener<MessageWrapper<...>>` 形式接收，并提取 message 对象处理，增强了消费端结构一致性与代码复用能力。

### 5. 改造收益

- 原来发送消息部分需要 20 行左右代码，现在仅需 1-2 行；
- 对于新增业务，仅需继承模板类并实现两个方法即可；
- 发送与消费的参数结构标准统一、便于排查与监控。

------

## 二、面试官可能问的问题与我的回答

### Q1：为什么选用模板方法而不是策略模式、责任链等？

**答：\**本场景下主要问题在于\**消息发送的流程结构一致，但参数组装差异化**，而且流程的执行顺序固定（构建消息 → 发送 → 打日志）。模板方法天然适合这种**“流程稳定但局部可变”**的场景。相比策略模式（通常用于行为切换），模板方法更简洁，更适用于统一流程管控。

------

### Q2：你对模板方法设计模式的理解是？

**答：\**模板方法是一种行为型设计模式，它\**在抽象类中定义一个算法的骨架**，并**将某些步骤延迟到子类中实现**。它强调复用稳定流程，并允许子类定制具体步骤。本质上是“定义不变，扩展可变”。

在这次改造中，我将**消息发送流程（构建配置 → 构建消息体 → 执行发送）**作为骨架固化在抽象类中，而将 topic、tag、消息体内容的个性化组装留给子类实现。

------

### Q3：你为什么要对消息体进行包装（MessageWrapper）？

**答：**主要出于以下几点考虑：

1. **通用性增强**：后续每类 Event 不需要关心 keys、时间等元信息，统一封装；
2. **兼容性增强**：方便统一消费结构 `RocketMQListener<MessageWrapper<T>>`；
3. **可观测性提升**：加入发送时间、唯一 key，便于排查消息链路；
4. **后续拓展方便**：如加入 traceId、userId 做日志串联都可以在 wrapper 中统一实现。

------

### Q4：RocketMQ 消息失败了你如何处理？有没有考虑幂等？

**答：**当前发送是同步发送 `syncSend()`，RocketMQ 自带重试机制。但生产端失败我会打印结构化日志，包括 keys 和事件体。

幂等方面，实际执行逻辑在消费者完成，我会在消费前校验 couponTask 状态，避免重复发放。

------

### Q5：如果将来切换到 Kafka，你这套架构还能复用吗？

**答：**可以的。我们的抽象模板中 RocketMQ 的操作仅集中在一个父类中，切换为 Kafka 只需更换 sendMessage 内部实现，不影响子类定义的构建逻辑。实际消息体、配置结构也基本可以复用。